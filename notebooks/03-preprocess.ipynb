{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc425a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import contractions\n",
    "import html\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adaeece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30946 entries, 0 to 30945\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   reviewId              30946 non-null  object        \n",
      " 1   userName              30946 non-null  object        \n",
      " 2   userImage             30946 non-null  object        \n",
      " 3   content               30937 non-null  object        \n",
      " 4   score                 30946 non-null  int64         \n",
      " 5   thumbsUpCount         30946 non-null  int64         \n",
      " 6   reviewCreatedVersion  27933 non-null  object        \n",
      " 7   at                    30946 non-null  datetime64[ns]\n",
      " 8   replyContent          8529 non-null   object        \n",
      " 9   repliedAt             8529 non-null   object        \n",
      " 10  appVersion            27933 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(8)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"../data/raw_reviews.csv\")\n",
    "df['at'] = pd.to_datetime(df['at'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fde4274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing review: 30937\n",
      "After dropping duplicates: 28280\n",
      "After keeping only string-type reviews: 28280\n"
     ]
    }
   ],
   "source": [
    "# Drop missing content\n",
    "df = df.dropna(subset=[\"content\"])\n",
    "print(f\"After dropping missing review: {len(df)}\")\n",
    "\n",
    "# Drop duplicates based on review\n",
    "df = df.drop_duplicates(subset=[\"content\"])\n",
    "print(f\"After dropping duplicates: {len(df)}\")\n",
    "\n",
    "# Keep only rows where 'review' is an actual string\n",
    "df = df[df[\"content\"].apply(lambda x: isinstance(x, str))]\n",
    "print(f\"After keeping only string-type reviews: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80442781",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "negation_words = {\"no\", \"not\", \"nor\", \"never\", \"n't\", \"dont\"}\n",
    "stop_words = stop_words - negation_words\n",
    "post_lemmatization_corrections = {\n",
    "    \"datum\": \"data\",\n",
    "    \"cannot\": \"can_not\",\n",
    "    \"dont\": \"do_not\",\n",
    "    \"doesnt\": \"does_not\",\n",
    "    \"wont\": \"will_not\",\n",
    "    \"cant\": \"can_not\",\n",
    "    \"isnt\": \"is_not\",\n",
    "    \"wasnt\": \"was_not\",\n",
    "    \"arent\": \"are_not\"\n",
    "}\n",
    "\n",
    "def sentiment_preprocessing(text: str) -> str:\n",
    "    # 1. Decode HTML entities: &amp; → &, etc.\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # 2. Normalize curly quotes to straight quotes\n",
    "    text = re.sub(r'[“”]', '\"', text)        # curly double quotes\n",
    "    text = re.sub(r\"[‘’]\", \"'\", text)        # curly single quotes\n",
    "\n",
    "    # 3. Collapse duplicate quotes (\"\" → \")\n",
    "    text = re.sub(r'\"\"', '\"', text)\n",
    "    text = re.sub(r\"''\", \"'\", text)\n",
    "\n",
    "    # 4. Remove literal \\n, \\t, \\r from escaped strings\n",
    "    text = re.sub(r'\\\\[nrt]+', ' ', text)\n",
    "\n",
    "    # 5. Remove URLs and mentions\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"@\\w+\", \" \", text)\n",
    "\n",
    "    # 6. Expand contractions (can't → can not)\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # 7. Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 8. Keep only useful punctuation: ! ? % '\n",
    "    #    Remove: . , : ; ( ) etc.\n",
    "    text = re.sub(r\"[^\\w\\s!?%']\", \" \", text)\n",
    "\n",
    "    # 9. Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Tokenize & lemmatize\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    skip_next = False\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "\n",
    "        lemma = token.lemma_.lower()\n",
    "        lemma = post_lemmatization_corrections.get(lemma, lemma)\n",
    "\n",
    "        # Preserve negation + meaningful word (negation tagging)\n",
    "        if lemma in negation_words and i + 1 < len(doc):\n",
    "            next_token = doc[i + 1]\n",
    "            if next_token.pos_ in {\"ADJ\", \"VERB\", \"ADV\", \"NOUN\"}:\n",
    "                next_lemma = next_token.lemma_.lower()\n",
    "                next_lemma = post_lemmatization_corrections.get(next_lemma, next_lemma)\n",
    "                tokens.append(f\"{lemma}_{next_lemma}\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "            else:\n",
    "                tokens.append(lemma)\n",
    "        elif lemma not in stop_words and token.is_alpha and len(lemma) > 1:\n",
    "            tokens.append(lemma)\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"cleaned_content\"] = df[\"content\"].apply(sentiment_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcf8454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing review: 28280\n",
      "After dropping duplicates: 26500\n",
      "After keeping only string-type reviews: 26500\n"
     ]
    }
   ],
   "source": [
    "# Drop missing content\n",
    "df = df.dropna(subset=[\"cleaned_content\"])\n",
    "print(f\"After dropping missing review: {len(df)}\")\n",
    "\n",
    "# Drop duplicates based on review\n",
    "df = df.drop_duplicates(subset=[\"cleaned_content\"])\n",
    "print(f\"After dropping duplicates: {len(df)}\")\n",
    "\n",
    "# Keep only rows where 'review' is an actual string\n",
    "df = df[df[\"cleaned_content\"].apply(lambda x: isinstance(x, str))]\n",
    "print(f\"After keeping only string-type reviews: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a25fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDIT - Komoot is the best app for walks!.. Rea...</td>\n",
       "      <td>edit komoot good app walk really good app sham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the offline maps and route tracking are very u...</td>\n",
       "      <td>offline map route tracking useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are you insane? 800$ yearly for the app and I ...</td>\n",
       "      <td>insane yearly app not_use buy campgroud trail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sooooo many cool trails :)</td>\n",
       "      <td>sooooo many cool trail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  EDIT - Komoot is the best app for walks!.. Rea...   \n",
       "1  the offline maps and route tracking are very u...   \n",
       "2                                               Nice   \n",
       "3  are you insane? 800$ yearly for the app and I ...   \n",
       "4                         sooooo many cool trails :)   \n",
       "\n",
       "                                     cleaned_content  \n",
       "0  edit komoot good app walk really good app sham...  \n",
       "1                  offline map route tracking useful  \n",
       "2                                               nice  \n",
       "3  insane yearly app not_use buy campgroud trail ...  \n",
       "4                             sooooo many cool trail  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(r\"../data/cleaned_reviews.csv\", index=False)\n",
    "df[[\"content\", \"cleaned_content\"]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
